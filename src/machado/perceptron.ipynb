{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://towardsdatascience.com/perceptron-algorithm-in-python-f3ac89d2e537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "\n",
    "    def __init__ (self):\n",
    "        self.columns = ['x', 'y', 'labels']\n",
    "\n",
    "    def makeDF(self):\n",
    "        return pd.DataFrame(self.makeData(), columns=self.columns)\n",
    "        \n",
    "    def makeData(self):\n",
    "        _x, _y = datasets.make_blobs(\n",
    "            n_samples = number_of_points,\n",
    "            n_features = 2,\n",
    "            centers = 2,\n",
    "            cluster_std = 1.05,\n",
    "            random_state = 2)\n",
    "        return list(zip(_x[:,0], _x[:,1], _y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "\n",
    "    def plot(self, df):\n",
    "        sns.scatterplot(\n",
    "            x = df.columns[0], \n",
    "            y = df.columns[1], \n",
    "            data = df,\n",
    "            hue = df.columns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomData: \n",
    "\n",
    "    def __init__(self, number_of_points):\n",
    "        self.df = Generator().makeDF(number_of_points)\n",
    "        self.plotter = Plotter()\n",
    "\n",
    "    def plot(self):\n",
    "        self.plotter.plot(self.generator.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.epochs = 100\n",
    "        self.learning_rate = 0.1\n",
    "        self.data = data\n",
    "        self.labels = self.data.iloc[:,-1]\n",
    "        self.samples = self.data.iloc[:,:-1]\n",
    "        self.sample_count = self.samples.shape[0]\n",
    "        self.feature_count  = self.samples.shape[1]\n",
    "        self.theta = np.zeros((self.feature_count + 1, 1))\n",
    "        self.activation_function = ActivationFunction(0.0)\n",
    "        self.miscalssified_counts = []\n",
    "\n",
    "    def train():\n",
    "        for _ in range(epochs):\n",
    "            for _i, _sample_i in enumerate(self.samples):\n",
    "                self.misclassified_counts[_i] = 0\n",
    "\n",
    "    def neuron(index, sample):\n",
    "        _prediction = self.predict(sample)\n",
    "        self.evaluate_prediction(index, sample, _prediction)\n",
    "    \n",
    "    def predict(sample):\n",
    "        _processed_sample = np.insert(sample, 0, 1).reshape(-1,1)\n",
    "        _dot_product = np.dot(_processed_sample.T, _theta)\n",
    "        _prediction = self.activation_function.check(_dot_product)\n",
    "        return _prediction\n",
    "    \n",
    "    def evaluate_prediction(index, sample, prediction):\n",
    "        if np.squeeze(prediction, self.labels[index]) == 0:\n",
    "            return\n",
    "        self.update_theta(index, sample, prediction)\n",
    "        self.increment_misclassification_count(index)\n",
    "\n",
    "    def update_theta(index, sample, prediction):\n",
    "        self.theta += self.learning_rate*sample*(self.labels(index) - prediction)\n",
    "\n",
    "    def increment_misclassification_count(index):\n",
    "        self.misclassified_count[index] += 1\n",
    "\n",
    "    def print_initialization(self):\n",
    "        print(f'epochs: {self.epochs}')\n",
    "        print(f'learning rate: {self.learning_rate}')\n",
    "        print(f'sample count: {self.sample_count}')\n",
    "        print(f'feature count: {self.feature_count}\\n')\n",
    "        print(f'samples:\\n{self.samples.head()}\\n')\n",
    "        print(f'labels:\\n{self.labels.head()}\\n')\n",
    "        print(f'theta:\\n{self.theta}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "\n",
    "    def __init__(self, threashold):\n",
    "        self.threashold = threashold\n",
    "\n",
    "    def check(self, data):\n",
    "        return [activate(_x) if _x > self.threashold else deactivate(_x) for _x in data]\n",
    "\n",
    "    def activate(self, data):\n",
    "        return 1.0\n",
    "\n",
    "    def deactivate(self, data):\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'number_of_points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [150]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _data \u001b[38;5;241m=\u001b[39m \u001b[43mRandomData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m _perceptron \u001b[38;5;241m=\u001b[39m Perceptron(_data\u001b[38;5;241m.\u001b[39mdf)\n\u001b[1;32m      3\u001b[0m _perceptron\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "Input \u001b[0;32mIn [147]\u001b[0m, in \u001b[0;36mRandomData.__init__\u001b[0;34m(self, number_of_points)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, number_of_points):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmakeDF(number_of_points)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplotter \u001b[38;5;241m=\u001b[39m Plotter()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'number_of_points'"
     ]
    }
   ],
   "source": [
    "_data = RandomData(250)\n",
    "_perceptron = Perceptron(_data.df)\n",
    "_perceptron.epochs = 10\n",
    "_perceptron.print_initialization()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2aa1287cf967b8824e97fd8dee4c5a26384cc030f77905b18432f9527a35a017"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
